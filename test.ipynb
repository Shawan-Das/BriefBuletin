{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting requests_html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from requests_html) (2.28.1)\n",
            "Collecting fake-useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting w3lib\n",
            "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "     -------------------------------------- 83.4/83.4 kB 778.1 kB/s eta 0:00:00\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: certifi>=2021 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (2022.9.14)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from pyppeteer>=0.0.14->requests_html) (1.26.11)\n",
            "Collecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Collecting websockets<11.0,>=10.0\n",
            "  Downloading websockets-10.3-cp39-cp39-win_amd64.whl (98 kB)\n",
            "     ---------------------------------------- 98.6/98.6 kB 2.9 MB/s eta 0:00:00\n",
            "Collecting appdirs<2.0.0,>=1.4.3\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting tqdm<5.0.0,>=4.42.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "     ---------------------------------------- 78.5/78.5 kB 2.2 MB/s eta 0:00:00\n",
            "Collecting importlib-metadata>=1.4\n",
            "  Using cached importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
            "Collecting beautifulsoup4\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "     -------------------------------------- 128.2/128.2 kB 3.8 MB/s eta 0:00:00\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting lxml>=2.1\n",
            "  Downloading lxml-4.9.1-cp39-cp39-win_amd64.whl (3.6 MB)\n",
            "     ---------------------------------------- 3.6/3.6 MB 1.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from requests->requests_html) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from requests->requests_html) (2.0.4)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.8.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from tqdm<5.0.0,>=4.42.1->pyppeteer>=0.0.14->requests_html) (0.4.5)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Building wheels for collected packages: bs4, fake-useragent, parse\n",
            "  Building wheel for bs4 (setup.py): started\n",
            "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=bdaaff46088d0861df42d6d9ee65c3b383f4e85ada6a8168fcf064012ac6f00c\n",
            "  Stored in directory: c:\\users\\darkt\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
            "  Building wheel for fake-useragent (setup.py): started\n",
            "  Building wheel for fake-useragent (setup.py): finished with status 'done'\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13481 sha256=19c40d4b49c6aee5f9ef0b464a2922b46db4d9572359c0879c24573f332553a8\n",
            "  Stored in directory: c:\\users\\darkt\\appdata\\local\\pip\\cache\\wheels\\ae\\e7\\76\\7dd44644d065268ab0e1b4fa2e802fa4bb0157717b7d6c6d92\n",
            "  Building wheel for parse (setup.py): started\n",
            "  Building wheel for parse (setup.py): finished with status 'done'\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24571 sha256=1ca870eecf498a7908fca1f363eb204369c784c2ee308e4d57309d0686a80c41\n",
            "  Stored in directory: c:\\users\\darkt\\appdata\\local\\pip\\cache\\wheels\\d6\\9c\\58\\ee3ba36897e890f3ad81e9b730791a153fce20caa4a8a474df\n",
            "Successfully built bs4 fake-useragent parse\n",
            "Installing collected packages: pyee, parse, fake-useragent, appdirs, zipp, websockets, w3lib, tqdm, soupsieve, lxml, cssselect, pyquery, importlib-metadata, beautifulsoup4, pyppeteer, bs4, requests_html\n",
            "Successfully installed appdirs-1.4.4 beautifulsoup4-4.11.1 bs4-0.0.1 cssselect-1.1.0 fake-useragent-0.1.11 importlib-metadata-4.12.0 lxml-4.9.1 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests_html-0.10.0 soupsieve-2.3.2.post1 tqdm-4.64.1 w3lib-2.0.1 websockets-10.3 zipp-3.8.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install requests_html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "session = HTMLSession()\n",
        "r = session.get(\"http://google.com\")\n",
        "\n",
        "html_str = r.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AL6rzSboF-Ch"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\darkt\\AppData\\Local\\Temp\\ipykernel_19584\\3400752061.py:12: RuntimeWarning: coroutine 'HTML.arender' was never awaited\n",
            "  r.html.arender(sleep=1, scrolldown=5)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "#import what we need\n",
        "import nest_asyncio\n",
        "from requests_html import HTMLSession, AsyncHTMLSession\n",
        "\n",
        "nest_asyncio.apply()\n",
        "session = AsyncHTMLSession()\n",
        "\n",
        "#use session to get the page\n",
        "r = await session.get('https://news.google.com/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGRqTVhZU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US%3Aen&v2prv=1')\n",
        "\n",
        "#render the html, sleep=1 to give it a second to finish before moving on. scrolldown= how many times to page down on the browser, to get more results. 5 was a good number here\n",
        "r.html.arender(sleep=1, scrolldown=5)\n",
        "\n",
        "#find all the articles by using inspect element and create blank list\n",
        "articles = r.html.find('article')\n",
        "newslist = []\n",
        "\n",
        "#loop through each article to find the title and link. try and except as repeated articles from other sources have different h tags.\n",
        "for item in articles:\n",
        "    try:\n",
        "        newsitem = item.find('h3', first=True)\n",
        "        title = newsitem.text\n",
        "        link = newsitem.absolute_links\n",
        "        newsarticle = {\n",
        "            'title': title,\n",
        "            'link': link \n",
        "        }\n",
        "        newslist.append(newsarticle)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "#print the length of the list\n",
        "print(len(newslist))\n",
        "# for i in range(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "     -------------------------------------- 211.1/211.1 kB 1.3 MB/s eta 0:00:00\n",
            "Collecting PyYAML>=3.11\n",
            "  Using cached PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
            "Collecting nltk>=3.2.1\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "     ---------------------------------------- 1.5/1.5 MB 1.2 MB/s eta 0:00:00\n",
            "Collecting jieba3k>=0.35.1\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "     ---------------------------------------- 7.4/7.4 MB 361.6 kB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting tldextract>=2.0.1\n",
            "  Downloading tldextract-3.3.1-py3-none-any.whl (93 kB)\n",
            "     -------------------------------------- 93.6/93.6 kB 530.9 kB/s eta 0:00:00\n",
            "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from Newspaper3k) (4.9.1)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from Newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from Newspaper3k) (1.1.0)\n",
            "Collecting Pillow>=3.3.0\n",
            "  Using cached Pillow-9.2.0-cp39-cp39-win_amd64.whl (3.3 MB)\n",
            "Collecting feedparser>=5.2.1\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "     -------------------------------------- 81.1/81.1 kB 566.9 kB/s eta 0:00:00\n",
            "Requirement already satisfied: requests>=2.10.0 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from Newspaper3k) (2.28.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from Newspaper3k) (4.11.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from beautifulsoup4>=4.4.1->Newspaper3k) (2.3.2.post1)\n",
            "Requirement already satisfied: six in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from feedfinder2>=0.0.4->Newspaper3k) (1.16.0)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: tqdm in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from nltk>=3.2.1->Newspaper3k) (4.64.1)\n",
            "Collecting click\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "     -------------------------------------- 96.6/96.6 kB 550.0 kB/s eta 0:00:00\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "     ------------------------------------ 298.0/298.0 kB 635.2 kB/s eta 0:00:00\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.9.13-cp39-cp39-win_amd64.whl (267 kB)\n",
            "     ------------------------------------ 267.7/267.7 kB 166.6 kB/s eta 0:00:00\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from requests>=2.10.0->Newspaper3k) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from requests>=2.10.0->Newspaper3k) (1.26.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from requests>=2.10.0->Newspaper3k) (2022.9.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from requests>=2.10.0->Newspaper3k) (3.3)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Collecting filelock>=3.0.8\n",
            "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\darkt\\anaconda3\\envs\\se\\lib\\site-packages (from click->nltk>=3.2.1->Newspaper3k) (0.4.5)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py): started\n",
            "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=9bf498abd64a1c6b73e43acd04e07ebb8de684ecc8531464f6b63bbcfeadeee1\n",
            "  Stored in directory: c:\\users\\darkt\\appdata\\local\\pip\\cache\\wheels\\94\\ad\\df\\a2a01300cea47d5695f242f7e925a805970106fd9e4b151468\n",
            "  Building wheel for feedfinder2 (setup.py): started\n",
            "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=e1404108f0dbf1fbac0bbe0fe9da4664e876cf633b48c68905bf25408b11e561\n",
            "  Stored in directory: c:\\users\\darkt\\appdata\\local\\pip\\cache\\wheels\\43\\4a\\c2\\61a371b2524ac90805391c660d8dc4505705297f25e2b85a5d\n",
            "  Building wheel for jieba3k (setup.py): started\n",
            "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398381 sha256=beb1d53c24a33ebdc38212740f2a93641a0df5d584778f18d92b6e5efb4452b4\n",
            "  Stored in directory: c:\\users\\darkt\\appdata\\local\\pip\\cache\\wheels\\c2\\22\\59\\8214a8d6357e9f540ce1f37f9a4362b6156b4ca81b37f1945f\n",
            "  Building wheel for sgmllib3k (setup.py): started\n",
            "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=61d96663a58a7687f456d17c95f86be0e794a8192c3769f98bb460a9b8ef2fcc\n",
            "  Stored in directory: c:\\users\\darkt\\appdata\\local\\pip\\cache\\wheels\\65\\7a\\a7\\78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, regex, PyYAML, Pillow, joblib, filelock, feedparser, click, requests-file, nltk, feedfinder2, tldextract, Newspaper3k\n",
            "Successfully installed Newspaper3k-0.2.8 Pillow-9.2.0 PyYAML-6.0 click-8.1.3 feedfinder2-0.0.4 feedparser-6.0.10 filelock-3.8.0 jieba3k-0.35.1 joblib-1.2.0 nltk-3.7 regex-2022.9.13 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install Newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\darkt\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from newspaper import Article\n",
        "# create an article object\n",
        "article = Article('https://www.thedailystar.net/tech-startup/news/serious-security-flaws-found-whatsapp-3130271')\n",
        "article.download()\n",
        "article.parse()\n",
        "article.nlp()\n",
        "title = article.title\n",
        "link = article.url\n",
        "authors = article.authors\n",
        "date = article.publish_date\n",
        "image = article.top_image\n",
        "summary = article.summary\n",
        "text = article.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************\n",
            "Title: Serious security flaws found in WhatsApp\n",
            "Link: https://www.thedailystar.net/tech-startup/news/serious-security-flaws-found-whatsapp-3130271\n",
            "Author: ['Toggle Desk']\n",
            "Publish Date: 2022-09-28 19:49:31+06:00\n",
            "Top Image: https://images.thedailystar.net/sites/default/files/styles/social_share/public/images/2022/09/28/dimitri-karastelev-ynjawgrwslm-unsplash.jpg\n",
            "Summary: \n",
            "Two serious security flaws have been found in WhatsApp, according to a report in The Sun.\n",
            "The report claims that by exploiting the security flaws, cybercriminals can remotely take over WhatsApp users' accounts at will.\n",
            "WhatsApp has reportedly quickly fixed the errors but due to the bugs remaining in the old version, users can get exposed still.\n",
            "By exploiting the flaws in the Android and iOS versions of WhatsApp, hackers can send malicious video files anonymously during video calls.\n",
            "The critical flaws were first identified by members of WhatsApp's internal security team, reports The Sun.\n",
            "**********************************\n"
          ]
        }
      ],
      "source": [
        "print('**********************************')\n",
        "print(f'Title: {title}')\n",
        "print(f'Link: {link}')\n",
        "print(f'Author: {authors}')\n",
        "print(f'Publish Date: {date}')\n",
        "print(f'Top Image: {image}')\n",
        "print(f'Summary: ')\n",
        "print(summary)\n",
        "print('**********************************')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('se')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "fd44f9802bcd1526b2b8dcd5d6e5308c3e1855235faa0ff41422a00b81beb28a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
